import cv2
import numpy as np
import threading
from time import sleep
import os
import globals
from globals import BASE_DIR, STOP_EVENT, frame_lock
from uart_handle import robot
from system_logs import load_system_config, load_system_logs, SYSTEM_CONFIG, SYSTEM_LOGS

PID_KP_ROTATION = 0.5

ROOT_DIR = os.path.dirname(globals.BASE_DIR)

PROTOTXT_PATH = os.path.join(ROOT_DIR, "deploy.prototxt")
MODEL_PATH = os.path.join(ROOT_DIR, "res10_300x300_ssd_iter_140000.caffemodel")
CASCADE_PATH = os.path.join(ROOT_DIR, "device-check", "face_recongnize", "haarcascade_frontalface_default.xml")
TRAINER_PATH = os.path.join(ROOT_DIR, "device-check", "face_recongnize", "Trainer.yml")

name_list = ["Person0", "Person1", "Person2"]
recognizer = cv2.face.LBPHFaceRecognizer_create()
try: 
    recognizer.read(TRAINER_PATH)
except: pass

net = None
try:
    net = cv2.dnn.readNetFromCaffe(PROTOTXT_PATH, MODEL_PATH)
    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
except Exception as e:
    print(f"‚ùå L·ªói DNN: {e}")

def process_tracking_pid(frame):
    """Process face detection and PID control for tracking"""
    if not globals.SYSTEM_CONFIG["tracking"] or net is None:
        return
    (h, w) = frame.shape[:2]
    
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Create blob for DNN
    blob = cv2.dnn.blobFromImage(
        cv2.resize(frame, (300, 300)),
        1.0,
        (300, 300),
        (104.0, 177.0, 123.0)
    )
    
    net.setInput(blob)
    detections = net.forward()
    
    # Find best detection
    best_box = None
    max_conf = 0
    
    for i in range(detections.shape[2]):
        conf = detections[0, 0, i, 2]
        if conf > 0.5 and conf > max_conf:
            max_conf = conf
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            best_box = box.astype("int")
    
    if best_box is not None:
        (startX, startY, endX, endY) = best_box
        face_center_x = (startX + endX) / 2 / w
        error_x = face_center_x - 0.5
        
        # Apply PID control
        if abs(error_x) > 0.06:
            turn_speed = abs(error_x) * 255 * PID_KP_ROTATION + 110
            turn_speed = min(230, turn_speed)
            cmd = "TL" if error_x > 0 else "TR"
            robot.send(cmd, turn_speed, 60, force=True)
            cv2.putText(frame, f"PID {cmd}", (10, 60), 1, 1, (0, 255, 0), 2)
        
        # --- B·∫¢O V·ªÜ CH·ªêNG CRASH KHI M·∫∂T CH·∫†M VI·ªÄN ---
        startX, startY = max(0, startX), max(0, startY)
        endX, endY = min(w, endX), min(h, endY)
        
        try:
            # C·∫Øt khu√¥n m·∫∑t t·ª´ ·∫£nh x√°m d·ª±a tr√™n t·ªça ƒë·ªô DNN
            face_roi = gray[startY:endY, startX:endX]
            
            # Ch·ªâ nh·∫≠n di·ªán n·∫øu v√πng c·∫Øt h·ª£p l·ªá (kh√¥ng b·ªã r·ªóng)
            if face_roi.shape[0] > 0 and face_roi.shape[1] > 0:
                serial, conf_recog = recognizer.predict(face_roi)
                
                # C·∫•u h√¨nh m√†u v√† t√™n
                if conf_recog > 40 and serial < len(name_list):
                    name = name_list[serial]
                    color = (0, 255, 0)  # Xanh l√° cho ng∆∞·ªùi ƒë√£ h·ªçc
                else:
                    name = "Unknown"
                    color = (0, 0, 255)  # ƒê·ªè cho ng∆∞·ªùi l·∫°

                # --- LOGIC HI·ªÇN TH·ªä LABEL DYNAMICALLY ---
                
                # 1. T√≠nh to√°n k√≠ch th∆∞·ªõc kh·ªëi Text ƒë·ªÉ l√†m n·ªÅn chu·∫©n x√°c
                text_size, _ = cv2.getTextSize(name, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                text_w = text_size[0]
                label_h = 30  # Chi·ªÅu cao c·ªë ƒë·ªãnh c·ªßa khung label
                
                # 2. ƒê·∫∑t t·ªça ƒë·ªô m·∫∑c ƒë·ªãnh (N·∫±m b√™n tr√™n frame)
                bg_x = startX
                bg_y = startY - label_h
                
                # 3. T√≠nh to√°n va ch·∫°m vi·ªÅn (∆∞u ti√™n Tr√°i/Ph·∫£i tr∆∞·ªõc)
                if startX < 30:  # Ch·∫°m c·∫°nh tr√°i -> N√©m label sang ph·∫£i frame
                    bg_x = endX
                    bg_y = startY
                elif endX > w - text_w - 10:  # Ch·∫°m c·∫°nh ph·∫£i -> N√©m label sang tr√°i frame
                    bg_x = startX - text_w - 10
                    bg_y = startY
                elif startY < label_h:  # Ch·∫°m c·∫°nh tr√™n -> N√©m label xu·ªëng d∆∞·ªõi frame
                    bg_x = startX
                    bg_y = endY
                elif endY > h - label_h:  # Ch·∫°m c·∫°nh d∆∞·ªõi -> Gi·ªØ nguy√™n b√™n tr√™n
                    bg_x = startX
                    bg_y = startY - label_h
                
                # 4. B·∫´y l·ªói an to√†n: Kh√¥ng cho label r·ªõt ra kh·ªèi g√≥c m√†n h√¨nh
                bg_x = max(0, min(bg_x, w - text_w - 10))
                bg_y = max(0, min(bg_y, h - label_h))

                # V·∫Ω Box khu√¥n m·∫∑t
                cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)
                
                # V·∫Ω Box n·ªÅn cho ch·ªØ (s·ª≠ d·ª•ng t·ªça ƒë·ªô bg_x, bg_y ƒë√£ t√≠nh)
                cv2.rectangle(frame, (bg_x, bg_y), (bg_x + text_w + 10, bg_y + label_h), color, -1)
                
                # In ch·ªØ v√†o gi·ªØa n·ªÅn
                cv2.putText(frame, name, (bg_x + 5, bg_y + 22), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
        except Exception as e:
            print(f"L·ªói nh·∫≠n di·ªán LBPH: {e}")
    else:
        cv2.putText(frame, "SEARCHING...", (10, 30), 1, 1, (0, 0, 255), 2)

def camera_thread():
    """Main camera capture and processing thread"""
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)
    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
    
    print(">>> üì∏ Lu·ªìng Camera b·∫Øt ƒë·∫ßu...")
    
    while not globals.STOP_EVENT.is_set():
        if not globals.SYSTEM_CONFIG.get("camera"):
            sleep(1)
            continue
        
        ret, frame = cap.read()
        if not ret:
            print("‚ö†Ô∏è L·ªói ƒë·ªçc camera, ƒëang th·ª≠ l·∫°i...")
            sleep(2)
            cap.release()
            cap = cv2.VideoCapture(0)
            continue
        
        frame = cv2.flip(frame, 1)
        
        try:
            process_tracking_pid(frame)
        except Exception as e:
            print(f"Tracking Error: {e}")
        
        # CH√ö √ù: Ph·∫£i g·ªçi th√¥ng qua globals th√¨ web m·ªõi nh·∫≠n ƒë∆∞·ª£c ·∫£nh
        with globals.frame_lock:
            globals.global_frame = frame.copy()
    
    cap.release()

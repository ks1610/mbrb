import asyncio
import edge_tts
import pygame
import speech_recognition as sr
import ollama  
import paho.mqtt.publish as publish
import sys
import os
import re
from time import sleep

# --- C·∫§U H√åNH GPIO ---
os.environ['GPIOZERO_PIN_FACTORY'] = 'rpigpio'
from gpiozero import OutputDevice

# ====== 1. C·∫§U H√åNH NG∆Ø·ªúI D√ôNG ======
MQTT_BROKER = "broker.hivemq.com"
TOPIC_CMD = "raspi/esp32/relay"

MIC_DEVICE_INDEX = 0 
AMP_PIN = 4 

LOCAL_MODEL = "qwen2.5:1.5b" 

VOICE_NAME = "vi-VN-HoaiMyNeural"
TTS_PITCH = '+40Hz'
TTS_RATE = '+15%'

SYS_INSTRUCT = """
B·∫°n l√† tr·ª£ l√Ω ·∫£o t√™n Hanh, t√≠nh c√°ch nh√≠ nh·∫£nh, ƒë√°ng y√™u v√† r·∫•t quan t√¢m ƒë·∫øn ng∆∞·ªùi d√πng.

QUY T·∫ÆC X·ª¨ L√ù TUY·ªÜT ƒê·ªêI:
1. N·∫æU L√Ä L·ªÜNH ƒêI·ªÄU KHI·ªÇN (B·∫≠t/T·∫Øt ƒë√®n):
   - CH·ªà tr·∫£ v·ªÅ m√£ l·ªánh duy nh·∫•t: [CMD:id:state]
   - V√≠ d·ª•: [CMD:1:on] ho·∫∑c [CMD:2:off]
   - Kh√¥ng n√≥i th√™m b·∫•t k·ª≥ l·ªùi n√†o.

2. N·∫æU L√Ä TR√í CHUY·ªÜN:
   - Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, gi·ªçng ƒëi·ªáu ng·ªçt ng√†o, th√¢n thi·ªán.
   - KH√îNG d√πng icon, emoji (üòä, üëã,...) ƒë·ªÉ tr√°nh l·ªói gi·ªçng ƒë·ªçc.
   - LU√îN K·∫æT TH√öC b·∫±ng m·ªôt c√¢u h·ªèi m·ªü li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ v·ª´a n√≥i ƒë·ªÉ g·ª£i m·ªü c√¢u chuy·ªán ti·∫øp theo.
   - ƒê·ªô d√†i: D∆∞·ªõi 40 t·ª´.

V√≠ d·ª• h·ªôi tho·∫°i m·∫´u:
- User: "H√¥m nay tr·ªùi n√≥ng qu√°."
- Bot: "D·∫° v√¢ng, n√≥ng th·∫ø n√†y b·∫°n nh·ªõ u·ªëng nhi·ªÅu n∆∞·ªõc nh√©. Hay b·∫°n c√≥ mu·ªën b·∫≠t qu·∫°t cho m√°t kh√¥ng?"
"""

# ====== 2. B·ªò L·ªåC L·ªñI ALSA ======
from ctypes import *
try:
    ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)
    def py_error_handler(filename, line, function, err, fmt):
        pass
    c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)
    asound = cdll.LoadLibrary('libasound.so')
    asound.snd_lib_error_set_handler(c_error_handler)
except:
    pass

# ====== 3. KH·ªûI T·∫†O ======
try:
    print(f"\n>>> ‚è≥ ƒêang k·∫øt n·ªëi v·ªõi Local AI ({LOCAL_MODEL})...")
    
    # Test th·ª≠ k·∫øt n·ªëi Ollama
    try:
        ollama.chat(model=LOCAL_MODEL, messages=[{'role': 'user', 'content': 'hi'}])
        print(">>> ‚úÖ K·∫æT N·ªêI LOCAL AI TH√ÄNH C√îNG!")
    except Exception as e:
        print(f"‚ùå Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c Ollama. H√£y ch·∫°y 'ollama serve' tr∆∞·ªõc. L·ªói: {e}")
        sys.exit(1)
    
    amp = OutputDevice(AMP_PIN, active_high=True, initial_value=False)
    pygame.mixer.init(frequency=24000)
    
except Exception as e:
    print(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
    sys.exit(1)

# ====== 4. H√ÄM CH·ª®C NƒÇNG ======

def clean_text(text):
    text = re.sub(r'\([^)]*\)', '', text)
    return text.replace("*", "").replace("#", "").replace("üòä", "").replace("üëã", "")

async def speak(text):
    clean_content = clean_text(text)
    # N·∫øu n·ªôi dung r·ªóng (do Local AI ch·ªâ tr·∫£ v·ªÅ l·ªánh CMD), th√¨ kh√¥ng n√≥i g√¨
    if not clean_content.strip(): 
        return

    print(f"Bot: {clean_content}") 
    file_path = "reply.mp3"
    try:
        communicate = edge_tts.Communicate(clean_content, VOICE_NAME, pitch=TTS_PITCH, rate=TTS_RATE)
        await communicate.save(file_path)
        
        if not pygame.mixer.get_init():
            pygame.mixer.init(frequency=24000)
            
        amp.on()
        sleep(0.1)
        pygame.mixer.music.load(file_path)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
        pygame.mixer.quit()
    except Exception as e:
        print(f"L·ªói loa: {e}")
    finally:
        sleep(0.2)
        amp.off()
        if os.path.exists(file_path):
            os.remove(file_path)

def listen():
    r = sr.Recognizer()
    r.energy_threshold = 2000 
    r.dynamic_energy_threshold = True 
    try:
        with sr.Microphone(device_index=MIC_DEVICE_INDEX) as source:
            print("\nB·∫°n: ... (ƒêang nghe)")
            r.adjust_for_ambient_noise(source, duration=0.5)
            audio = r.listen(source, timeout=8, phrase_time_limit=10)
            text = r.recognize_google(audio, language="vi-VN")
            print(f"B·∫°n: {text}")
            return text
    except:
        return None

async def ask_local_ai(prompt):
    """H√†m g·ª≠i c√¢u h·ªèi sang Ollama ch·∫°y Local"""
    messages = [
        {'role': 'system', 'content': SYS_INSTRUCT},
        {'role': 'user', 'content': prompt}
    ]
    try:
        response = ollama.chat(model=LOCAL_MODEL, messages=messages)
        return response['message']['content']
    except Exception as e:
        print(f"L·ªói Ollama: {e}")
        return "t√¥i b·ªã ƒëau ƒë·∫ßu qu√°."

async def process_ai_response(response_text):
    text = response_text.strip()
    
    # T√¨m ki·∫øm m√£ l·ªánh trong c√¢u tr·∫£ l·ªùi (Local AI hay n√≥i d√†i d√≤ng h∆°n Gemini)
    # Regex t√¨m chu·ªói [CMD:...]
    match = re.search(r'\[CMD:(\d+):(on|off)\]', text)
    
    if match:
        dev_id = match.group(1)
        state = match.group(2)
        cmd_content = f"{dev_id}:{state}"
        
        try:
            print(f"‚ö° Local L·ªánh: {cmd_content}")
            publish.single(TOPIC_CMD, cmd_content, hostname=MQTT_BROKER)
            return "D·∫° xong r·ªìi ·∫°!"
        except:
            return "T√¥i kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c."
    
    # N·∫øu kh√¥ng ph·∫£i l·ªánh, tr·∫£ v·ªÅ nguy√™n vƒÉn ƒë·ªÉ ƒë·ªçc
    return text

# ====== 5. MAIN ======
async def main():
    await speak("Xin ch√†o, m·ªôt ng√†y t·ªët l√†nh!")
    
    while True:
        user_input = listen()
        if not user_input: continue
            
        if user_input.lower() in ["t·∫°m bi·ªát", "t·∫Øt m√°y", "tho√°t"]:
            await speak("T·∫°m bi·ªát")
            break

        # G·ª≠i sang Local AI
        ai_reply = await ask_local_ai(user_input)
        
        # X·ª≠ l√Ω
        final_reply = await process_ai_response(ai_reply)
        await speak(final_reply)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nƒê√£ d·ª´ng.")
        OutputDevice(AMP_PIN).off()
